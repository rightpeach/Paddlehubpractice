{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "题目1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "import paddlehub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "2.0.4\n"
     ]
    }
   ],
   "source": [
    "print(paddle.__version__)\n",
    "print(hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n",
      "+-------------------------+--------------------------------------------------+\n",
      "|       ModuleName        |Path                                              |\n",
      "+-------------------------+--------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!hub list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "题目2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar (child): data/thu_news.tar.gz: Cannot open: No such file or directory\r\n",
      "tar (child): Error is not recoverable: exiting now\r\n",
      "tar: Child returned status 2\r\n",
      "tar: Error is not recoverable: exiting now\r\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf data/thu_news.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/aistudio/thu_news/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_a\tlabel\r\n",
      "直击特里勾手助小牛反超神鸟发威火箭仍处劣势　　新浪体育讯　北京时间4月16日消息，火箭今天迎来常规赛的收官战。客场挑战达拉斯小牛的比赛将关系到火箭队最终的排名，目前西部的竞争仍然非常激励。尤其是西部第二到第七的六支球队将在今天展开捉对厮杀的情况下，黄蜂、小牛、开拓者以及马刺都有可能是火箭队的下一个对手。以下为本场比赛的精彩瞬间——　　第四节比赛还剩下8分多钟，姚明重新回到场上，但是小牛队的霍里随后在右翼接队友传球后上演一记三分跳投，虽然身体动作已经变形，但是他仍然将球命中，随后基德在弧顶处的一记三分跳投帮助小牛终于将比分反超，火箭在进攻中直接打不开局面，而小牛更是利用特里空切后的一记勾手将比分反超至4分，包括库班在内的所有小牛现场球迷都站起来振臂高呼，而此时阿德尔曼还在场边低头深沉的思索中。　　比赛还剩下最后5分多钟，洛瑞带球突破中被小牛队员犯规，洛瑞来不及刹车让自己直接撞到了观众席上，右腿疼痛难忍的他脸都几乎变形，结果他两罚两中，火箭队还落后两分。随后，洛瑞将球直接传给此时已经回到场上的阿泰，野兽此时将球稳下，并没有急于进攻，随后他顺势将球塞给兰德里，神鸟利用对方站位空隙直接杀到篮下，上篮成功，火箭将比分终于追至80平。场上局面对于火箭来说绝对是不容有失。　　(sabrina)\t体育\r\n",
      "北京网购年消费额112亿元　　商报讯(记者吴文治)昨日，淘宝网发布的《2009-2010年度中国网购热门城市报告》显示，北京年度网购消费力达112.5亿元，与上海相差近62亿元，位列十大热门消费力城市第二位。此外，男性网购的消费金额高出女性，与“女性是网购主力军”的传统观念不符。　　淘宝公布的报告显示，中国网购消费力十大城市分别是上海、北京、深圳、杭州、广州、南京、苏州、天津、温州和宁波。主要集中在以江浙沪为主的长三角地区、以广深为主的珠三角地区和以北京为主的京津地区。北京年度网购112.5亿元的消费额，占国内城市网购消费额的5.6%。　　中国网购消费力十大城市的消费金额性别来源比例中，男性占比超过了女性。前者占比达到53.5%，后者则为46.5%。不过，在成交人数、成交笔数等关键数据上显示，女性消费者均高于男性。此外，在十大网购热门城市中，25岁-34岁的群体成为网购消费的主力军，占比达到62.49%。\t科技\r\n",
      "世界首辆飞行汽车成功试飞(附图)　　新快报讯据美国《时代杂志》等媒体19日报道，世界首辆飞行汽车本月初在美国实现了首飞，降落后只需按一个按钮就可将机翼折叠，驶上高速公路。　　据报道，美国特拉弗吉亚公司研发的这辆名为“特拉弗吉亚过渡”的飞行汽车的空中巡航时速可达185公里，它还可以在道路上行驶，可以安全地存放在车库里。公司称，汽车可以用一箱汽油在空中飞行643公里。与此同时，飞行汽车加油时只需驶入最近的加油站，向油箱里加入无铅汽油即可。人们先前也曾验证过其它飞行汽车，但特拉弗吉亚公司研发的飞行汽车是第一辆拥有可折叠机翼的、并能无缝隙地实现从空中降落到公路的汽车。不过，这辆车的门槛还有点高，车的价格达13.9万英镑（约合135万元人民币）。\t社会\r\n"
     ]
    }
   ],
   "source": [
    "!head -4 thu_news/valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "事业测试：你工作易受他人干扰吗(图)　　独家撰稿：苑椿　心理测试征稿启事 欢迎关注新浪星座微博　　办公室永远是个龙蛇混杂、藏龙卧虎的地方，你永远不知道一张张面具底下会是怎样的脸庞，你是否还傻傻的对别人的话听之任之，完全搞乱了自己工作的步调？还是笃定的坚守阵地，从未被谣言动摇分毫？赶紧来测测看吧！　　(本测试仅供娱乐，非专业心理指导。)\t星座\r\n",
      "趣味测试：你怎么红红火火过春节(图)　　独家撰稿：岚　心理测试征稿启事 欢迎关注新浪星座微博　　红红火火过大年啦，每年的此时你都会如何度过呢？是跟家人爱人在一起还是跟朋友兄弟外出欢聚呢？亦或背起行囊远离嘈杂，无论如何，总会有一种适合你的方式，赶紧来测测看吧！　　(本测试仅供娱乐，非专业心理指导。)\t星座\r\n",
      "人际测试：你的人际磁场强大吗(图)　　独家撰稿：大智若笨　心理测试征稿启事　　如何在草木皆兵的office里脱颖而出，最好的办法不是到处抱怨也不是埋头工作，而是要加强自己的磁场，让周围的人都被你所感染，如此有影响力，你难道还怕自己不能夺人眼球吗。　　独家撰稿：大智若笨　心理测试征稿启事　　如何在草木皆兵的office里脱颖而出，最好的办法不是到处抱怨也不是埋头工作，而是要加强自己的磁场，让周围的人都被你所感染，如此有影响力，你难道还怕自己不能夺人眼球吗。\t星座\r\n"
     ]
    }
   ],
   "source": [
    "!tail -3 thu_news/valid.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "题目3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlehub.datasets.base_nlp_dataset import TextClassificationDataset\n",
    "\n",
    "class MyDataset(TextClassificationDataset):\n",
    "    base_path = \"/home/aistudio/thu_news/\"\n",
    "    label_list = ['体育', '科技', '社会', '娱乐', '股票', '房产', '教育', '时政', '财经', '星座', '游戏', '家居', '彩票', '时尚']\n",
    "\n",
    "    def __init__(self, tokenizer, max_seq_len: int=256, mode:str='train'):\n",
    "        if mode == 'train':\n",
    "            data_file = 'train-1.csv'\n",
    "        elif mode == 'test':\n",
    "            data_file = 'test-1.csv'\n",
    "        else:\n",
    "            data_file = 'valid-1.csv'\n",
    "        \n",
    "        super().__init__(\n",
    "            base_path=self.base_path,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_len=max_seq_len,\n",
    "            mode=mode,\n",
    "            data_file=data_file,\n",
    "            label_list=self.label_list,\n",
    "            is_file_with_header=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-13 19:17:32,076 - INFO - Lock 139649082926736 acquired on /home/aistudio/.paddlehub/tmp/ernie\n",
      "[INFO 2021-04-13 19:17:32,076 filelock.py:274] Lock 139649082926736 acquired on /home/aistudio/.paddlehub/tmp/ernie\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download https://bj.bcebos.com/paddlehub/paddlehub_dev/ernie_2.0.2.tar.gz\n",
      "[##################################################] 100.00%\n",
      "Decompress /home/aistudio/.paddlehub/tmp/tmp7yf1240i/ernie_2.0.2.tar.gz\n",
      "[##################################################] 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-13 19:17:32,591] [    INFO] - Successfully installed ernie-2.0.2\n",
      "2021-04-13 19:17:32,595 - INFO - Lock 139649082926736 released on /home/aistudio/.paddlehub/tmp/ernie\n",
      "[INFO 2021-04-13 19:17:32,595 filelock.py:318] Lock 139649082926736 released on /home/aistudio/.paddlehub/tmp/ernie\n",
      "[2021-04-13 19:17:32,597] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/ernie/ernie_v1_chn_base.pdparams and saved to /home/aistudio/.paddlenlp/models/ernie-1.0\n",
      "[2021-04-13 19:17:32,600] [    INFO] - Downloading ernie_v1_chn_base.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/ernie/ernie_v1_chn_base.pdparams\n",
      "100%|██████████| 390123/390123 [00:07<00:00, 51245.38it/s]\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1303: UserWarning: Skip loading for classifier.weight. classifier.weight is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1303: UserWarning: Skip loading for classifier.bias. classifier.bias is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n"
     ]
    }
   ],
   "source": [
    "model = hub.Module(name='ernie', version='2.0.2', task='seq-cls', num_classes=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-13 19:17:48,438] [    INFO] - Downloading vocab.txt from https://paddlenlp.bj.bcebos.com/models/transformers/ernie/vocab.txt\n",
      "100%|██████████| 89/89 [00:00<00:00, 3306.43it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = model.get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(tokenizer)\n",
    "valid_dataset = MyDataset(tokenizer, mode='valid')\n",
    "test_dataset = MyDataset(tokenizer, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-13 19:20:52,437] [ WARNING] - PaddleHub model checkpoint not found, start from scratch...\n"
     ]
    }
   ],
   "source": [
    "optimizer = paddle.optimizer.Adam(learning_rate=5e-5, parameters=model.parameters())\n",
    "trainer = hub.Trainer(model, optimizer, checkpoint_dir='./ckpt', use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-13 19:21:36,115] [   TRAIN] - Epoch=1/3, Step=10/282 loss=2.3801 acc=0.2594 lr=0.000050 step/sec=2.21 | ETA 00:06:22\n",
      "[2021-04-13 19:21:40,343] [   TRAIN] - Epoch=1/3, Step=20/282 loss=1.6804 acc=0.5594 lr=0.000050 step/sec=2.36 | ETA 00:06:10\n",
      "[2021-04-13 19:21:44,569] [   TRAIN] - Epoch=1/3, Step=30/282 loss=1.2243 acc=0.7063 lr=0.000050 step/sec=2.37 | ETA 00:06:05\n",
      "[2021-04-13 19:21:48,801] [   TRAIN] - Epoch=1/3, Step=40/282 loss=0.8484 acc=0.7969 lr=0.000050 step/sec=2.36 | ETA 00:06:03\n",
      "[2021-04-13 19:21:53,037] [   TRAIN] - Epoch=1/3, Step=50/282 loss=0.6292 acc=0.8531 lr=0.000050 step/sec=2.36 | ETA 00:06:02\n",
      "[2021-04-13 19:21:57,282] [   TRAIN] - Epoch=1/3, Step=60/282 loss=0.6719 acc=0.8219 lr=0.000050 step/sec=2.36 | ETA 00:06:02\n",
      "[2021-04-13 19:22:01,528] [   TRAIN] - Epoch=1/3, Step=70/282 loss=0.5422 acc=0.8594 lr=0.000050 step/sec=2.36 | ETA 00:06:01\n",
      "[2021-04-13 19:22:05,791] [   TRAIN] - Epoch=1/3, Step=80/282 loss=0.4363 acc=0.9062 lr=0.000050 step/sec=2.35 | ETA 00:06:01\n",
      "[2021-04-13 19:22:10,046] [   TRAIN] - Epoch=1/3, Step=90/282 loss=0.3305 acc=0.9156 lr=0.000050 step/sec=2.35 | ETA 00:06:01\n",
      "[2021-04-13 19:22:14,301] [   TRAIN] - Epoch=1/3, Step=100/282 loss=0.3126 acc=0.9125 lr=0.000050 step/sec=2.35 | ETA 00:06:01\n",
      "[2021-04-13 19:22:18,562] [   TRAIN] - Epoch=1/3, Step=110/282 loss=0.2892 acc=0.9250 lr=0.000050 step/sec=2.35 | ETA 00:06:01\n",
      "[2021-04-13 19:22:22,842] [   TRAIN] - Epoch=1/3, Step=120/282 loss=0.3857 acc=0.8906 lr=0.000050 step/sec=2.34 | ETA 00:06:01\n",
      "[2021-04-13 19:22:27,118] [   TRAIN] - Epoch=1/3, Step=130/282 loss=0.2904 acc=0.9281 lr=0.000050 step/sec=2.34 | ETA 00:06:01\n",
      "[2021-04-13 19:22:31,396] [   TRAIN] - Epoch=1/3, Step=140/282 loss=0.2027 acc=0.9500 lr=0.000050 step/sec=2.34 | ETA 00:06:01\n",
      "[2021-04-13 19:22:35,662] [   TRAIN] - Epoch=1/3, Step=150/282 loss=0.3117 acc=0.9250 lr=0.000050 step/sec=2.34 | ETA 00:06:01\n",
      "[2021-04-13 19:22:39,925] [   TRAIN] - Epoch=1/3, Step=160/282 loss=0.3249 acc=0.9250 lr=0.000050 step/sec=2.35 | ETA 00:06:01\n",
      "[2021-04-13 19:22:44,195] [   TRAIN] - Epoch=1/3, Step=170/282 loss=0.2945 acc=0.9156 lr=0.000050 step/sec=2.34 | ETA 00:06:01\n",
      "[2021-04-13 19:22:48,466] [   TRAIN] - Epoch=1/3, Step=180/282 loss=0.2741 acc=0.9313 lr=0.000050 step/sec=2.34 | ETA 00:06:01\n",
      "[2021-04-13 19:22:52,741] [   TRAIN] - Epoch=1/3, Step=190/282 loss=0.3429 acc=0.9125 lr=0.000050 step/sec=2.34 | ETA 00:06:01\n",
      "[2021-04-13 19:22:57,007] [   TRAIN] - Epoch=1/3, Step=200/282 loss=0.2328 acc=0.9406 lr=0.000050 step/sec=2.34 | ETA 00:06:01\n",
      "[2021-04-13 19:23:01,271] [   TRAIN] - Epoch=1/3, Step=210/282 loss=0.2967 acc=0.9250 lr=0.000050 step/sec=2.35 | ETA 00:06:01\n",
      "[2021-04-13 19:23:05,558] [   TRAIN] - Epoch=1/3, Step=220/282 loss=0.2143 acc=0.9250 lr=0.000050 step/sec=2.33 | ETA 00:06:01\n",
      "[2021-04-13 19:23:09,843] [   TRAIN] - Epoch=1/3, Step=230/282 loss=0.3004 acc=0.9187 lr=0.000050 step/sec=2.33 | ETA 00:06:01\n",
      "[2021-04-13 19:23:14,142] [   TRAIN] - Epoch=1/3, Step=240/282 loss=0.2655 acc=0.9187 lr=0.000050 step/sec=2.33 | ETA 00:06:01\n",
      "[2021-04-13 19:23:18,419] [   TRAIN] - Epoch=1/3, Step=250/282 loss=0.2796 acc=0.9094 lr=0.000050 step/sec=2.34 | ETA 00:06:01\n",
      "[2021-04-13 19:23:22,710] [   TRAIN] - Epoch=1/3, Step=260/282 loss=0.2249 acc=0.9375 lr=0.000050 step/sec=2.33 | ETA 00:06:01\n",
      "[2021-04-13 19:23:26,994] [   TRAIN] - Epoch=1/3, Step=270/282 loss=0.2283 acc=0.9344 lr=0.000050 step/sec=2.33 | ETA 00:06:01\n",
      "[2021-04-13 19:23:31,283] [   TRAIN] - Epoch=1/3, Step=280/282 loss=0.2431 acc=0.9313 lr=0.000050 step/sec=2.33 | ETA 00:06:01\n",
      "[2021-04-13 19:23:38,514] [    EVAL] - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - [Evaluation result] avg_acc=0.8907\n",
      "[2021-04-13 19:24:00,671] [    EVAL] - Saving best model to ./ckpt/best_model [best acc=0.8907]\n",
      "[2021-04-13 19:24:00,675] [    INFO] - Saving model checkpoint to ./ckpt/epoch_1\n",
      "[2021-04-13 19:24:23,110] [   TRAIN] - Epoch=2/3, Step=10/282 loss=0.1811 acc=0.9531 lr=0.000050 step/sec=0.23 | ETA 00:08:16\n",
      "[2021-04-13 19:24:27,364] [   TRAIN] - Epoch=2/3, Step=20/282 loss=0.1261 acc=0.9688 lr=0.000050 step/sec=2.35 | ETA 00:08:12\n",
      "[2021-04-13 19:24:31,634] [   TRAIN] - Epoch=2/3, Step=30/282 loss=0.1469 acc=0.9625 lr=0.000050 step/sec=2.34 | ETA 00:08:08\n",
      "[2021-04-13 19:24:35,921] [   TRAIN] - Epoch=2/3, Step=40/282 loss=0.1654 acc=0.9563 lr=0.000050 step/sec=2.33 | ETA 00:08:04\n",
      "[2021-04-13 19:24:40,193] [   TRAIN] - Epoch=2/3, Step=50/282 loss=0.1557 acc=0.9437 lr=0.000050 step/sec=2.34 | ETA 00:08:00\n",
      "[2021-04-13 19:24:44,484] [   TRAIN] - Epoch=2/3, Step=60/282 loss=0.2371 acc=0.9313 lr=0.000050 step/sec=2.33 | ETA 00:07:57\n",
      "[2021-04-13 19:24:48,774] [   TRAIN] - Epoch=2/3, Step=70/282 loss=0.2365 acc=0.9281 lr=0.000050 step/sec=2.33 | ETA 00:07:53\n",
      "[2021-04-13 19:24:53,051] [   TRAIN] - Epoch=2/3, Step=80/282 loss=0.1610 acc=0.9594 lr=0.000050 step/sec=2.34 | ETA 00:07:50\n",
      "[2021-04-13 19:24:57,321] [   TRAIN] - Epoch=2/3, Step=90/282 loss=0.2038 acc=0.9469 lr=0.000050 step/sec=2.34 | ETA 00:07:47\n",
      "[2021-04-13 19:25:01,601] [   TRAIN] - Epoch=2/3, Step=100/282 loss=0.1414 acc=0.9688 lr=0.000050 step/sec=2.34 | ETA 00:07:45\n",
      "[2021-04-13 19:25:05,905] [   TRAIN] - Epoch=2/3, Step=110/282 loss=0.1395 acc=0.9531 lr=0.000050 step/sec=2.32 | ETA 00:07:42\n",
      "[2021-04-13 19:25:10,187] [   TRAIN] - Epoch=2/3, Step=120/282 loss=0.1608 acc=0.9594 lr=0.000050 step/sec=2.34 | ETA 00:07:40\n",
      "[2021-04-13 19:25:14,467] [   TRAIN] - Epoch=2/3, Step=130/282 loss=0.1135 acc=0.9750 lr=0.000050 step/sec=2.34 | ETA 00:07:37\n",
      "[2021-04-13 19:25:18,755] [   TRAIN] - Epoch=2/3, Step=140/282 loss=0.1634 acc=0.9531 lr=0.000050 step/sec=2.33 | ETA 00:07:35\n",
      "[2021-04-13 19:25:23,052] [   TRAIN] - Epoch=2/3, Step=150/282 loss=0.1683 acc=0.9656 lr=0.000050 step/sec=2.33 | ETA 00:07:33\n",
      "[2021-04-13 19:25:27,335] [   TRAIN] - Epoch=2/3, Step=160/282 loss=0.1300 acc=0.9563 lr=0.000050 step/sec=2.33 | ETA 00:07:31\n",
      "[2021-04-13 19:25:31,635] [   TRAIN] - Epoch=2/3, Step=170/282 loss=0.1330 acc=0.9625 lr=0.000050 step/sec=2.33 | ETA 00:07:29\n",
      "[2021-04-13 19:25:35,933] [   TRAIN] - Epoch=2/3, Step=180/282 loss=0.1668 acc=0.9594 lr=0.000050 step/sec=2.33 | ETA 00:07:27\n",
      "[2021-04-13 19:25:40,233] [   TRAIN] - Epoch=2/3, Step=190/282 loss=0.1643 acc=0.9500 lr=0.000050 step/sec=2.33 | ETA 00:07:25\n",
      "[2021-04-13 19:25:44,530] [   TRAIN] - Epoch=2/3, Step=200/282 loss=0.1231 acc=0.9625 lr=0.000050 step/sec=2.33 | ETA 00:07:23\n",
      "[2021-04-13 19:25:48,820] [   TRAIN] - Epoch=2/3, Step=210/282 loss=0.1379 acc=0.9781 lr=0.000050 step/sec=2.33 | ETA 00:07:22\n",
      "[2021-04-13 19:25:53,122] [   TRAIN] - Epoch=2/3, Step=220/282 loss=0.2090 acc=0.9406 lr=0.000050 step/sec=2.32 | ETA 00:07:20\n",
      "[2021-04-13 19:25:57,418] [   TRAIN] - Epoch=2/3, Step=230/282 loss=0.1784 acc=0.9469 lr=0.000050 step/sec=2.33 | ETA 00:07:19\n",
      "[2021-04-13 19:26:01,715] [   TRAIN] - Epoch=2/3, Step=240/282 loss=0.1116 acc=0.9719 lr=0.000050 step/sec=2.33 | ETA 00:07:17\n",
      "[2021-04-13 19:26:06,022] [   TRAIN] - Epoch=2/3, Step=250/282 loss=0.1449 acc=0.9719 lr=0.000050 step/sec=2.32 | ETA 00:07:16\n",
      "[2021-04-13 19:26:10,326] [   TRAIN] - Epoch=2/3, Step=260/282 loss=0.1203 acc=0.9594 lr=0.000050 step/sec=2.32 | ETA 00:07:15\n",
      "[2021-04-13 19:26:14,616] [   TRAIN] - Epoch=2/3, Step=270/282 loss=0.1182 acc=0.9625 lr=0.000050 step/sec=2.33 | ETA 00:07:13\n",
      "[2021-04-13 19:26:18,907] [   TRAIN] - Epoch=2/3, Step=280/282 loss=0.1618 acc=0.9469 lr=0.000050 step/sec=2.33 | ETA 00:07:12\n",
      "[2021-04-13 19:26:54,821] [    EVAL] - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Saving best model to ./ckpt/best_model [best acc=0.9050]\n",
      "[2021-04-13 19:26:54,825] [    INFO] - Saving model checkpoint to ./ckpt/epoch_2\n",
      "[2021-04-13 19:27:26,314] [   TRAIN] - Epoch=3/3, Step=10/282 loss=0.1197 acc=0.9688 lr=0.000050 step/sec=0.18 | ETA 00:08:42\n",
      "[2021-04-13 19:27:30,580] [   TRAIN] - Epoch=3/3, Step=20/282 loss=0.1476 acc=0.9656 lr=0.000050 step/sec=2.34 | ETA 00:08:40\n",
      "[2021-04-13 19:27:34,841] [   TRAIN] - Epoch=3/3, Step=30/282 loss=0.1083 acc=0.9688 lr=0.000050 step/sec=2.35 | ETA 00:08:37\n",
      "[2021-04-13 19:27:39,105] [   TRAIN] - Epoch=3/3, Step=40/282 loss=0.1018 acc=0.9688 lr=0.000050 step/sec=2.35 | ETA 00:08:34\n",
      "[2021-04-13 19:27:43,382] [   TRAIN] - Epoch=3/3, Step=50/282 loss=0.0675 acc=0.9875 lr=0.000050 step/sec=2.34 | ETA 00:08:32\n",
      "[2021-04-13 19:27:47,651] [   TRAIN] - Epoch=3/3, Step=60/282 loss=0.0660 acc=0.9844 lr=0.000050 step/sec=2.34 | ETA 00:08:29\n",
      "[2021-04-13 19:27:51,934] [   TRAIN] - Epoch=3/3, Step=70/282 loss=0.0789 acc=0.9750 lr=0.000050 step/sec=2.33 | ETA 00:08:27\n",
      "[2021-04-13 19:27:56,217] [   TRAIN] - Epoch=3/3, Step=80/282 loss=0.1083 acc=0.9688 lr=0.000050 step/sec=2.33 | ETA 00:08:25\n",
      "[2021-04-13 19:28:00,499] [   TRAIN] - Epoch=3/3, Step=90/282 loss=0.0672 acc=0.9812 lr=0.000050 step/sec=2.34 | ETA 00:08:23\n",
      "[2021-04-13 19:28:04,789] [   TRAIN] - Epoch=3/3, Step=100/282 loss=0.0768 acc=0.9781 lr=0.000050 step/sec=2.33 | ETA 00:08:20\n",
      "[2021-04-13 19:28:09,079] [   TRAIN] - Epoch=3/3, Step=110/282 loss=0.1472 acc=0.9688 lr=0.000050 step/sec=2.33 | ETA 00:08:18\n",
      "[2021-04-13 19:28:13,360] [   TRAIN] - Epoch=3/3, Step=120/282 loss=0.0801 acc=0.9781 lr=0.000050 step/sec=2.34 | ETA 00:08:16\n",
      "[2021-04-13 19:28:17,647] [   TRAIN] - Epoch=3/3, Step=130/282 loss=0.0956 acc=0.9781 lr=0.000050 step/sec=2.33 | ETA 00:08:14\n",
      "[2021-04-13 19:28:21,938] [   TRAIN] - Epoch=3/3, Step=140/282 loss=0.0987 acc=0.9719 lr=0.000050 step/sec=2.33 | ETA 00:08:13\n",
      "[2021-04-13 19:28:26,229] [   TRAIN] - Epoch=3/3, Step=150/282 loss=0.0645 acc=0.9781 lr=0.000050 step/sec=2.33 | ETA 00:08:11\n",
      "[2021-04-13 19:28:30,524] [   TRAIN] - Epoch=3/3, Step=160/282 loss=0.0734 acc=0.9781 lr=0.000050 step/sec=2.33 | ETA 00:08:09\n",
      "[2021-04-13 19:28:34,807] [   TRAIN] - Epoch=3/3, Step=170/282 loss=0.0945 acc=0.9781 lr=0.000050 step/sec=2.33 | ETA 00:08:07\n",
      "[2021-04-13 19:28:39,099] [   TRAIN] - Epoch=3/3, Step=180/282 loss=0.1114 acc=0.9719 lr=0.000050 step/sec=2.33 | ETA 00:08:06\n",
      "[2021-04-13 19:28:43,396] [   TRAIN] - Epoch=3/3, Step=190/282 loss=0.0956 acc=0.9812 lr=0.000050 step/sec=2.33 | ETA 00:08:04\n",
      "[2021-04-13 19:28:47,701] [   TRAIN] - Epoch=3/3, Step=200/282 loss=0.0983 acc=0.9781 lr=0.000050 step/sec=2.32 | ETA 00:08:02\n",
      "[2021-04-13 19:28:52,000] [   TRAIN] - Epoch=3/3, Step=210/282 loss=0.0738 acc=0.9844 lr=0.000050 step/sec=2.33 | ETA 00:08:01\n",
      "[2021-04-13 19:28:56,294] [   TRAIN] - Epoch=3/3, Step=220/282 loss=0.0941 acc=0.9625 lr=0.000050 step/sec=2.33 | ETA 00:07:59\n",
      "[2021-04-13 19:29:00,590] [   TRAIN] - Epoch=3/3, Step=230/282 loss=0.0960 acc=0.9812 lr=0.000050 step/sec=2.33 | ETA 00:07:58\n",
      "[2021-04-13 19:29:04,890] [   TRAIN] - Epoch=3/3, Step=240/282 loss=0.0942 acc=0.9812 lr=0.000050 step/sec=2.33 | ETA 00:07:56\n",
      "[2021-04-13 19:29:09,198] [   TRAIN] - Epoch=3/3, Step=250/282 loss=0.0837 acc=0.9688 lr=0.000050 step/sec=2.32 | ETA 00:07:55\n",
      "[2021-04-13 19:29:13,503] [   TRAIN] - Epoch=3/3, Step=260/282 loss=0.0822 acc=0.9750 lr=0.000050 step/sec=2.32 | ETA 00:07:54\n",
      "[2021-04-13 19:29:17,803] [   TRAIN] - Epoch=3/3, Step=270/282 loss=0.1204 acc=0.9656 lr=0.000050 step/sec=2.33 | ETA 00:07:52\n",
      "[2021-04-13 19:29:22,087] [   TRAIN] - Epoch=3/3, Step=280/282 loss=0.0939 acc=0.9812 lr=0.000050 step/sec=2.33 | ETA 00:07:51\n",
      "[2021-04-13 19:29:29,255] [    EVAL] - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - [Evaluation result] avg_acc=0.9086\n",
      "[2021-04-13 19:29:57,550] [    EVAL] - Saving best model to ./ckpt/best_model [best acc=0.9086]\n",
      "[2021-04-13 19:29:57,561] [    INFO] - Saving model checkpoint to ./ckpt/epoch_3\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_dataset, epochs=3, batch_size=32, eval_dataset=valid_dataset, save_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n",
      "+-------------------------+--------------------------------------------------+\n",
      "|       ModuleName        |Path                                              |\n",
      "+-------------------------+--------------------------------------------------+\n",
      "|          ernie          |/home/aistudio/.paddlehub/modules/ernie           |\n",
      "+-------------------------+--------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!hub list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-13 19:33:20,434] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\n",
      "[2021-04-13 19:33:27,458] [    INFO] - Loaded parameters from /home/aistudio/ckpt/best_model/model.pdparams\n",
      "[2021-04-13 19:33:27,607] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-1.0/vocab.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 昌平京基鹭府10月29日推别墅1200万套起享97折　　新浪房产讯(编辑郭彪)京基鹭府(论坛相册户型样板间点评地图搜索)售楼处位于昌平区京承高速北七家出口向西南公里路南。项目预计10月29日开盘，总价1200万元/套起，2012年年底入住。待售户型为联排户型面积为410-522平方米，独栋户型面积为938平方米，双拼户型面积为522平方米。　　京基鹭府项目位于昌平定泗路与东北路交界处。项目周边配套齐全，幼儿园：伊顿双语幼儿园、温莎双语幼儿园；中学：北师大亚太实验学校、潞河中学(北京市重点)；大学：王府语言学校、北京邮电大学、现代音乐学院；医院：王府中西医结合医院(三级甲等)、潞河医院、解放军263医院、安贞医院昌平分院；购物：龙德广场、中联万家商厦、世纪华联超市、瑰宝购物中心、家乐福超市；酒店：拉斐特城堡、鲍鱼岛；休闲娱乐设施：九华山庄、温都温泉度假村、小汤山疗养院、龙脉温泉度假村、小汤山文化广场、皇港高尔夫、高地高尔夫、北鸿高尔夫球场；银行：工商银行、建设银行、中国银行、北京农村商业银行；邮局：中国邮政储蓄；其它：北七家建材城、百安居建材超市、北七家镇武装部、北京宏翔鸿企业孵化基地等，享受便捷生活。 \t Lable: 房产\n",
      "Data: 尽管官方到今天也没有公布《使命召唤：现代战争2》的游戏详情，但《使命召唤：现代战争2》首部包含游戏画面的影片终于现身。虽然影片仅有短短不到20秒，但影片最后承诺大家将于美国时间5月24日NBA职业篮球东区决赛时将会揭露更多的游戏内容。　　这部只有18秒的广告片闪现了9个镜头，能够辨识的场景有直升机飞向海岛军事工事，有飞机场争夺战，有潜艇和水下工兵，有冰上乘具，以及其他的一些镜头。整体来看《现代战争2》很大可能仍旧与俄罗斯有关。　　片尾有一则预告：“May24th，EasternConferenceFinals”，这是什么？这是说当前美国NBA联赛东部总决赛的日期。原来这部视频是NBA季后赛奥兰多魔术对波士顿凯尔特人队时，TNT电视台播放的广告。 \t Lable: 游戏\n",
      "Data: 罗马锋王竟公然挑战两大旗帜拉涅利的球队到底错在哪　　记者张恺报道主场一球小胜副班长巴里无可吹捧，罗马占优也纯属正常，倒是托蒂罚失点球和前两号门将先后受伤(多尼以三号身份出场)更让人揪心。阵容规模扩大，反而表现不如上赛季，缺乏一流强队的色彩，这是所有球迷对罗马的印象。　　拉涅利说：“去年我们带着嫉妒之心看国米，今年我们也有了和国米同等的超级阵容，许多教练都想有罗马的球员。阵容广了，寻找队内平衡就难了，某些时段球员的互相排斥和跟从前相比的落差都正常。有好的一面，也有不好的一面，所幸，我们一直在说一支伟大的罗马，必胜的信念和够级别的阵容，我们有了。”拉涅利的总结由近一阶段困扰罗马的队内摩擦、个别球员闹意见要走人而发，本赛季技术层面强化的罗马一直没有上赛季反扑的面貌，内部变化值得球迷关注。 \t Lable: 体育\n",
      "Data: 新总督致力提高加拿大公立教育质量　　滑铁卢大学校长约翰斯顿先生于10月1日担任加拿大总督职务。约翰斯顿先生还曾任麦吉尔大学长，并曾在多伦多大学、女王大学和西安大略大学担任教学职位。　　约翰斯顿先生在就职演说中表示，要将加拿大建设成为一个“聪明与关爱的国度”。为实现这一目标，他提出三个支柱：支持并关爱家庭、儿童；鼓励学习与创造；提倡慈善和志愿者精神。他尤其强调要关爱并尊重教师，并通过公立教育使每个人的才智得到充分发展。 \t Lable: 教育\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    # 房产\n",
    "    [\"昌平京基鹭府10月29日推别墅1200万套起享97折　　新浪房产讯(编辑郭彪)京基鹭府(论坛相册户型样板间点评地图搜索)售楼处位于昌平区京承高速北七家出口向西南公里路南。项目预计10月29日开盘，总价1200万元/套起，2012年年底入住。待售户型为联排户型面积为410-522平方米，独栋户型面积为938平方米，双拼户型面积为522平方米。　　京基鹭府项目位于昌平定泗路与东北路交界处。项目周边配套齐全，幼儿园：伊顿双语幼儿园、温莎双语幼儿园；中学：北师大亚太实验学校、潞河中学(北京市重点)；大学：王府语言学校、北京邮电大学、现代音乐学院；医院：王府中西医结合医院(三级甲等)、潞河医院、解放军263医院、安贞医院昌平分院；购物：龙德广场、中联万家商厦、世纪华联超市、瑰宝购物中心、家乐福超市；酒店：拉斐特城堡、鲍鱼岛；休闲娱乐设施：九华山庄、温都温泉度假村、小汤山疗养院、龙脉温泉度假村、小汤山文化广场、皇港高尔夫、高地高尔夫、北鸿高尔夫球场；银行：工商银行、建设银行、中国银行、北京农村商业银行；邮局：中国邮政储蓄；其它：北七家建材城、百安居建材超市、北七家镇武装部、北京宏翔鸿企业孵化基地等，享受便捷生活。\"],\n",
    "    # 游戏\n",
    "    [\"尽管官方到今天也没有公布《使命召唤：现代战争2》的游戏详情，但《使命召唤：现代战争2》首部包含游戏画面的影片终于现身。虽然影片仅有短短不到20秒，但影片最后承诺大家将于美国时间5月24日NBA职业篮球东区决赛时将会揭露更多的游戏内容。　　这部只有18秒的广告片闪现了9个镜头，能够辨识的场景有直升机飞向海岛军事工事，有飞机场争夺战，有潜艇和水下工兵，有冰上乘具，以及其他的一些镜头。整体来看《现代战争2》很大可能仍旧与俄罗斯有关。　　片尾有一则预告：“May24th，EasternConferenceFinals”，这是什么？这是说当前美国NBA联赛东部总决赛的日期。原来这部视频是NBA季后赛奥兰多魔术对波士顿凯尔特人队时，TNT电视台播放的广告。\"],\n",
    "    # 体育\n",
    "    [\"罗马锋王竟公然挑战两大旗帜拉涅利的球队到底错在哪　　记者张恺报道主场一球小胜副班长巴里无可吹捧，罗马占优也纯属正常，倒是托蒂罚失点球和前两号门将先后受伤(多尼以三号身份出场)更让人揪心。阵容规模扩大，反而表现不如上赛季，缺乏一流强队的色彩，这是所有球迷对罗马的印象。　　拉涅利说：“去年我们带着嫉妒之心看国米，今年我们也有了和国米同等的超级阵容，许多教练都想有罗马的球员。阵容广了，寻找队内平衡就难了，某些时段球员的互相排斥和跟从前相比的落差都正常。有好的一面，也有不好的一面，所幸，我们一直在说一支伟大的罗马，必胜的信念和够级别的阵容，我们有了。”拉涅利的总结由近一阶段困扰罗马的队内摩擦、个别球员闹意见要走人而发，本赛季技术层面强化的罗马一直没有上赛季反扑的面貌，内部变化值得球迷关注。\"],\n",
    "    # 教育\n",
    "    [\"新总督致力提高加拿大公立教育质量　　滑铁卢大学校长约翰斯顿先生于10月1日担任加拿大总督职务。约翰斯顿先生还曾任麦吉尔大学长，并曾在多伦多大学、女王大学和西安大略大学担任教学职位。　　约翰斯顿先生在就职演说中表示，要将加拿大建设成为一个“聪明与关爱的国度”。为实现这一目标，他提出三个支柱：支持并关爱家庭、儿童；鼓励学习与创造；提倡慈善和志愿者精神。他尤其强调要关爱并尊重教师，并通过公立教育使每个人的才智得到充分发展。\"]\n",
    "]\n",
    "\n",
    "label_list=['体育', '科技', '社会', '娱乐', '股票', '房产', '教育', '时政', '财经', '星座', '游戏', '家居', '彩票', '时尚']\n",
    "label_map = { \n",
    "    idx: label_text for idx, label_text in enumerate(label_list)\n",
    "}\n",
    "\n",
    "model = hub.Module(\n",
    "    name='ernie',\n",
    "    task='seq-cls',\n",
    "    load_checkpoint='./ckpt/best_model/model.pdparams',\n",
    "    label_map=label_map)\n",
    "results = model.predict(data, max_seq_len=128, batch_size=1, use_gpu=False)\n",
    "for idx, text in enumerate(data):\n",
    "    print('Data: {} \\t Lable: {}'.format(text[0], results[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
